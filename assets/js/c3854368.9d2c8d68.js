"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[9845],{161:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/files/InferUDF-3352900112f57735d25911c3422b2723.zip"},502:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/udf_infer_project-3c93cfc55e03d73b1297ff68ae0071ce.png"},1429:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/submit_infer_job-e738160193fce775ed739365bbf711be.png"},3330:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/publish_infer_job-670a6006675534117c1cedf09ca11590.png"},3544:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/infer_result-4b631065dce3e13f2df92cebc76fb376.png"},5040:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>a,default:()=>d,frontMatter:()=>o,metadata:()=>c,toc:()=>l});var r=t(4848),i=t(8453);const o={},a="Quick Start (Running near line inference with UDF)",c={id:"quick_start/quick_start_infer&UDF",title:"Quick Start (Running near line inference with UDF)",description:"GeaFlow provides near-line model inference capabilities. Users only need to provide the Python file for model calling.",source:"@site/../docs-en/source/3.quick_start/3.quick_start_infer&UDF.md",sourceDirName:"3.quick_start",slug:"/quick_start/quick_start_infer&UDF",permalink:"/tugraph-analytics/en/quick_start/quick_start_infer&UDF",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{}},s={},l=[{value:"Prepare",id:"prepare",level:2},{value:"1. Compile GeaFlow Project",id:"1-compile-geaflow-project",level:3},{value:"2. Install docker",id:"2-install-docker",level:2},{value:"3. Prepare udf",id:"3-prepare-udf",level:2},{value:"3. Run udf in console",id:"3-run-udf-in-console",level:2}];function p(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"quick-start-running-near-line-inference-with-udf",children:"Quick Start (Running near line inference with UDF)"})}),"\n",(0,r.jsx)(n.p,{children:"GeaFlow provides near-line model inference capabilities. Users only need to provide the Python file for model calling.\nThere is no need to convert the model into an onnx model, which avoids the performance degradation caused by model conversion.\nAt the same time, it reduces the deployment difficulty for algorithm developers. This example shows how to use GeaFlow\nto call the AI model for inference and obtain model inference results during the near-line computing process.\nThe AI model in this example is a graph node classification model trained on Cora, a commonly used data set for GNN.\nGeaFlow reads the node id to construct a vertex, and then in the process of near-line calculation,\nSend the node ID to the python model inference process, call the AI model inference to obtain the node prediction type\nand the corresponding probability, and then return the result to the GeaFlow java process.\nThis example shows how to perform model reasoning through GeaFlow. In real scenarios, the logic of near-line\ncomputing may be more complex. Model reasoning is only a step in near-line computing.\nAfter obtaining the model results, complex iterative calculations can be performed, and the inference model can even\nbe called multiple times, which can be expanded as needed."}),"\n",(0,r.jsx)(n.h2,{id:"prepare",children:"Prepare"}),"\n",(0,r.jsx)(n.h3,{id:"1-compile-geaflow-project",children:"1. Compile GeaFlow Project"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Reference ",(0,r.jsx)(n.a,{href:"/tugraph-analytics/en/quick_start/quick_start",children:"1.quick_start.md"})]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2-install-docker",children:"2. Install docker"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Reference ",(0,r.jsx)(n.a,{href:"/tugraph-analytics/en/quick_start/quick_start_docker",children:"2.quick_start_docker.md"})]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"3-prepare-udf",children:"3. Prepare udf"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:t(161).A+"",children:"udf resources"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Structure of udf project"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"udf_project_structure",src:t(502).A+"",width:"680",height:"848"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"IncrGraphInferCompute implements IncVertexCentricCompute api.\nIn this method, the AI model is called for inference and the inference results are obtained."}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-java",children:'package org.example;\n\nimport com.antgroup.geaflow.api.function.io.SinkFunction;\nimport com.antgroup.geaflow.api.graph.compute.IncVertexCentricCompute;\nimport com.antgroup.geaflow.api.graph.function.vc.IncVertexCentricComputeFunction;\nimport com.antgroup.geaflow.api.graph.function.vc.VertexCentricCombineFunction;\nimport com.antgroup.geaflow.api.graph.function.vc.base.IncGraphInferContext;\nimport com.antgroup.geaflow.api.pdata.stream.window.PWindowSource;\nimport com.antgroup.geaflow.api.window.impl.SizeTumblingWindow;\nimport com.antgroup.geaflow.common.config.Configuration;\nimport com.antgroup.geaflow.common.config.keys.ExecutionConfigKeys;\nimport com.antgroup.geaflow.common.config.keys.FrameworkConfigKeys;\nimport com.antgroup.geaflow.common.type.primitive.IntegerType;\nimport com.antgroup.geaflow.env.Environment;\nimport com.antgroup.geaflow.env.EnvironmentFactory;\nimport com.antgroup.geaflow.example.function.FileSink;\nimport com.antgroup.geaflow.example.function.FileSource;\nimport com.antgroup.geaflow.file.FileConfigKeys;\nimport com.antgroup.geaflow.model.graph.edge.IEdge;\nimport com.antgroup.geaflow.model.graph.edge.impl.ValueEdge;\nimport com.antgroup.geaflow.model.graph.meta.GraphMetaType;\nimport com.antgroup.geaflow.model.graph.vertex.IVertex;\nimport com.antgroup.geaflow.model.graph.vertex.impl.ValueVertex;\nimport com.antgroup.geaflow.pipeline.IPipelineResult;\nimport com.antgroup.geaflow.pipeline.Pipeline;\nimport com.antgroup.geaflow.pipeline.PipelineFactory;\nimport com.antgroup.geaflow.pipeline.task.IPipelineTaskContext;\nimport com.antgroup.geaflow.pipeline.task.PipelineTask;\nimport com.antgroup.geaflow.view.GraphViewBuilder;\nimport com.antgroup.geaflow.view.IViewDesc.BackendType;\nimport com.antgroup.geaflow.view.graph.GraphViewDesc;\nimport com.antgroup.geaflow.view.graph.PGraphView;\nimport com.antgroup.geaflow.view.graph.PIncGraphView;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\n\npublic class IncrGraphInferCompute {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(IncrGraphInferCompute.class);\n\n    // Set result dir.\n    public static final String RESULT_FILE_PATH = "/tmp/geaflow";\n    public static final String INFER_PYTHON_CLASS_NAME = "myTransFormFunction";\n\n    public static void main(String[] args) {\n        Map<String, String> config = new HashMap<>();\n        config.put(ExecutionConfigKeys.JOB_APP_NAME.getKey(), IncrGraphInferCompute.class.getSimpleName());\n        config.put(FileConfigKeys.ROOT.getKey(), "/tmp/");\n        Environment environment = EnvironmentFactory.onLocalEnvironment(args);\n        Configuration configuration = environment.getEnvironmentContext().getConfig();\n\n        configuration.putAll(config);\n        IPipelineResult result = submit(environment);\n        result.get();\n    }\n\n    public static IPipelineResult<?> submit(Environment environment) {\n        final Pipeline pipeline = PipelineFactory.buildPipeline(environment);\n        Configuration envConfig = environment.getEnvironmentContext().getConfig();\n\n        envConfig.put(FrameworkConfigKeys.INFER_ENV_ENABLE, "true");\n        envConfig.put(FrameworkConfigKeys.INFER_ENV_USER_TRANSFORM_CLASSNAME, INFER_PYTHON_CLASS_NAME);\n        envConfig.put(FrameworkConfigKeys.INFER_ENV_INIT_TIMEOUT_SEC, "1800");\n        // Replace according to your hardware.\n        envConfig.put(FrameworkConfigKeys.INFER_ENV_CONDA_URL, "https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh");\n        envConfig.put(FileSink.OUTPUT_DIR, RESULT_FILE_PATH);\n\n        //build graph view\n        final String graphName = "graph_view_name";\n        GraphViewDesc graphViewDesc = GraphViewBuilder.createGraphView(graphName)\n                .withShardNum(1)\n                .withBackend(BackendType.RocksDB)\n                .withSchema(new GraphMetaType(IntegerType.INSTANCE, ValueVertex.class, Integer.class,\n                        ValueEdge.class, IntegerType.class))\n                .build();\n        pipeline.withView(graphName, graphViewDesc);\n        pipeline.submit(new PipelineTask() {\n            @Override\n            public void execute(IPipelineTaskContext pipelineTaskCxt) {\n                Configuration conf = pipelineTaskCxt.getConfig();\n                PWindowSource<IVertex<Integer, List<Object>>> vertices =\n                        // extract vertex from edge file\n                        pipelineTaskCxt.buildSource(new FileSource<>("data/Cora/node_ids.txt",\n                                line -> {\n                                    String[] fields = line.split(",");\n                                    IVertex<Integer, List<Object>> vertex = new ValueVertex<>(\n                                            Integer.valueOf(fields[0]), null);\n                                    return Arrays.asList(vertex);\n                                }), SizeTumblingWindow.of(10000))\n                                .withParallelism(1);\n\n                PWindowSource<IEdge<Integer, Integer>> edges =\n                        pipelineTaskCxt.buildSource(new com.antgroup.geaflow.example.function.FileSource<>("data/Cora/node_ids.txt",\n                                line -> {\n                                    String[] fields = line.split(",");\n                                    IEdge<Integer, Integer> edge = new ValueEdge<>(Integer.valueOf(fields[0]),\n                                            Integer.valueOf(fields[0]), 1);\n                                    return Collections.singletonList(edge);\n                                }), SizeTumblingWindow.of(5000));\n\n\n                PGraphView<Integer, List<Object>, Integer> fundGraphView =\n                        pipelineTaskCxt.getGraphView(graphName);\n\n                PIncGraphView<Integer, List<Object>, Integer> incGraphView =\n                        fundGraphView.appendGraph(vertices, edges);\n                int mapParallelism = 1;\n                int sinkParallelism = 1;\n                SinkFunction<String> sink = new FileSink<>();\n                incGraphView.incrementalCompute(new IncGraphAlgorithms(1))\n                        .getVertices()\n                        .map(v -> String.format("%s,%s", v.getId(), v.getValue()))\n                        .withParallelism(mapParallelism)\n                        .sink(sink)\n                        .withParallelism(sinkParallelism);\n            }\n        });\n\n        return pipeline.execute();\n    }\n\n    public static class IncGraphAlgorithms extends IncVertexCentricCompute<Integer, List<Object>,\n            Integer, Integer> {\n\n        public IncGraphAlgorithms(long iterations) {\n            super(iterations);\n        }\n\n        @Override\n        public IncVertexCentricComputeFunction<Integer, List<Object>, Integer, Integer> getIncComputeFunction() {\n            return new InferVertexCentricComputeFunction();\n        }\n\n        @Override\n        public VertexCentricCombineFunction<Integer> getCombineFunction() {\n            return null;\n        }\n\n    }\n\n    public static class InferVertexCentricComputeFunction implements\n            IncVertexCentricComputeFunction<Integer, List<Object>, Integer, Integer> {\n\n        private IncGraphComputeContext<Integer, List<Object>, Integer, Integer> graphContext;\n        private IncGraphInferContext<List<Object>> graphInferContext;\n\n        @Override\n        public void init(IncGraphComputeContext<Integer, List<Object>, Integer, Integer> graphContext) {\n            this.graphContext = graphContext;\n            this.graphInferContext = (IncGraphInferContext<List<Object>>) graphContext;\n        }\n\n        @Override\n        public void evolve(Integer vertexId,\n                           TemporaryGraph<Integer, List<Object>, Integer> temporaryGraph) {\n            long lastVersionId = 0L;\n            IVertex<Integer, List<Object>> vertex = temporaryGraph.getVertex();\n            HistoricalGraph<Integer, List<Object>, Integer> historicalGraph = graphContext\n                    .getHistoricalGraph();\n            if (vertex == null) {\n                vertex = historicalGraph.getSnapShot(lastVersionId).vertex().get();\n            }\n\n            if (vertex != null) {\n                // Call the AI model to predict the class to which the node belongs and the corresponding probability.  \n                List<Object> result = this.graphInferContext.infer(vertexId);\n                // Sink result.\n                graphContext.collect(vertex.withValue(result));\n                LOGGER.info("node-{} max prob: {}, predict class: {}", vertexId, result.get(0), result.get(1));\n            }\n        }\n\n        @Override\n        public void compute(Integer vertexId, Iterator<Integer> messageIterator) {\n        }\n\n        @Override\n        public void finish(Integer vertexId, MutableGraph<Integer, List<Object>, Integer> mutableGraph) {\n        }\n    }\n\n}\n'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["The AI inference model(Classify graph nodes in ",(0,r.jsx)(n.a,{href:"https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz",children:"Cora dataset"}),") is defined in the TransFormFunctionUDF.py file, as follows:"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import abc\nfrom typing import Union, List\nimport torch\nimport ast\nfrom torch_geometric.datasets import Planetoid\nfrom gcn_model import GCN\n\ndef safe_int(number):\n    try:\n        return int(number)\n    except:\n        return 0\n\n\ndef safe_float(number):\n    try:\n        return float(number)\n    except:\n        return 0.0\n\n\nclass TransFormFunction(abc.ABC):\n    def __init__(self, input_size):\n        self.input_size = input_size\n\n    @abc.abstractmethod\n    def load_model(self, *args):\n        pass\n\n    @abc.abstractmethod\n    def transform_pre(self, *args) -> Union[torch.Tensor, List[torch.Tensor]]:\n        pass\n\n    @abc.abstractmethod\n    def transform_post(self, *args):\n        pass\n\n\n# User class need to inherit TransFormFunction.\nclass myTransFormFunction(TransFormFunction):\n    def __init__(self):\n        super().__init__(1)\n        print(\"init myTransFormFunction\")\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.dataset = Planetoid(root='./data', name='Cora')\n        self.data = self.dataset[0].to(self.device)\n        self.load_model('model.pt')\n\n    def load_model(self, model_path: str):\n        model = GCN(self.dataset.num_node_features, self.dataset.num_classes).to(self.device)\n        model.load_state_dict(torch.load(model_path))\n        model.eval()\n        out = model(self.data)\n        self.prob = torch.exp(out)\n\n    # Define model infer logic.\n    def transform_pre(self, *args):\n        node_prob = self.prob[args[0]]\n        max_prob, max_class = node_prob.max(dim=0)\n        return [max_prob.item(), max_class.item()], [max_prob.item(), max_class.item()]\n\n    def transform_post(self, res):\n        return res\n\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Set the python dependencies required for model inference in requirements.txt, as follows:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"--index-url https://pypi.tuna.tsinghua.edu.cn/simple\ntorch\ntorchvision\ntorchaudio\ntorch-scatter\ntorch-sparse\ntorch-cluster\ntorch-spline-conv\ntorch-geometric\n"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"model.pt is the trained model file that needs to be used."}),"\n",(0,r.jsx)(n.li,{children:"The corresponding engine dependencies need to be introduced in pom.xml,\nand the version needs to be modified to the version of the GeaFlow engine you are using."}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0" encoding="UTF-8"?>\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>org.example</groupId>\n    <artifactId>InferUDF</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <packaging>jar</packaging>\n\n    <properties>\n        <maven.compiler.source>8</maven.compiler.source>\n        <maven.compiler.target>8</maven.compiler.target>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    </properties>\n    <dependencies>\n        <dependency>\n            <groupId>com.antgroup.tugraph</groupId>\n            <artifactId>geaflow-api</artifactId>\n            <version>0.5.0-SNAPSHOT</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.antgroup.tugraph</groupId>\n            <artifactId>geaflow-pdata</artifactId>\n            <version>0.5.0-SNAPSHOT</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.antgroup.tugraph</groupId>\n            <artifactId>geaflow-cluster</artifactId>\n            <version>0.5.0-SNAPSHOT</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.antgroup.tugraph</groupId>\n            <artifactId>geaflow-on-local</artifactId>\n            <version>0.5.0-SNAPSHOT</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.antgroup.tugraph</groupId>\n            <artifactId>geaflow-pipeline</artifactId>\n            <version>0.5.0-SNAPSHOT</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.antgroup.tugraph</groupId>\n            <artifactId>geaflow-infer</artifactId>\n            <version>0.5.0-SNAPSHOT</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.antgroup.tugraph</groupId>\n            <artifactId>geaflow-operator</artifactId>\n            <version>0.5.0-SNAPSHOT</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.antgroup.tugraph</groupId>\n            <artifactId>geaflow-api</artifactId>\n            <version>0.5.0-SNAPSHOT</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.antgroup.tugraph</groupId>\n            <artifactId>geaflow-common</artifactId>\n            <version>0.5.0-SNAPSHOT</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.antgroup.tugraph</groupId>\n            <artifactId>geaflow-examples</artifactId>\n            <version>0.5.0-SNAPSHOT</version>\n        </dependency>\n    </dependencies>\n</project>\n'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:'Execute the command "mvn clean install", and you can get the compiled udf package in the target directory.'}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"3-run-udf-in-console",children:"3. Run udf in console"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Create job\n",(0,r.jsx)(n.img,{alt:"create_job",src:t(9117).A+"",width:"3378",height:"1702"})]}),"\n",(0,r.jsxs)(n.li,{children:["Publish job\n",(0,r.jsx)(n.img,{alt:"publish_job",src:t(3330).A+"",width:"3066",height:"744"})]}),"\n",(0,r.jsxs)(n.li,{children:["Submit job\n",(0,r.jsx)(n.img,{alt:"submit_job",src:t(1429).A+"",width:"3052",height:"1138"})]}),"\n",(0,r.jsxs)(n.li,{children:["View results. The results are saved in the path /tmp/geaflow/result_0\n",(0,r.jsx)(n.img,{alt:"view_result",src:t(3544).A+"",width:"590",height:"960"})]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>c});var r=t(6540);const i={},o=r.createContext(i);function a(e){const n=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(o.Provider,{value:n},e.children)}},9117:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/create_infer_job-a0f512aa15eba0fa62900b87dae934d0.png"}}]);