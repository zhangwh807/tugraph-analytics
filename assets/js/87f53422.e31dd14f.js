"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[7234],{2917:(e,a,i)=>{i.d(a,{A:()=>t});const t=i.p+"assets/images/fantaoxian-6380d0955ee52acc4ee174f5db08653e.png"},3790:(e,a,i)=>{i.d(a,{A:()=>t});const t=i.p+"assets/images/guiyin_analysis-3054a7b804327090935d9ec2df9fae06.png"},4423:(e,a,i)=>{i.r(a),i.d(a,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>o,toc:()=>c});var t=i(4848),n=i(8453);const s={},r="Introduction",o={id:"introduction",title:"Introduction",description:"Background Introduction",source:"@site/../docs-en/source/2.introduction.md",sourceDirName:".",slug:"/introduction",permalink:"/tugraph-analytics/en/introduction",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Guide",permalink:"/tugraph-analytics/en/guide"},next:{title:"Quick Start (Running in Local)",permalink:"/tugraph-analytics/en/quick_start/quick_start"}},l={},c=[{value:"Background Introduction",id:"background-introduction",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Application Scenarios",id:"application-scenarios",level:2},{value:"Real-time Data Warehouse Acceleration",id:"real-time-data-warehouse-acceleration",level:3},{value:"Real-time Attribution Analysis",id:"real-time-attribution-analysis",level:3},{value:"Real-time Anti-Crash System",id:"real-time-anti-crash-system",level:3}];function h(e){const a={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,n.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(a.header,{children:(0,t.jsx)(a.h1,{id:"introduction",children:"Introduction"})}),"\n",(0,t.jsx)(a.h2,{id:"background-introduction",children:"Background Introduction"}),"\n",(0,t.jsx)(a.p,{children:"Early big data processing mainly relied on offline processing, with technologies like Hadoop effectively solving\nthe problem of analyzing large-scale data. However, processing efficiency was inadequate for high real-time demand scenarios. The emergence of stream computing engines, represented by Storm, effectively addressed the issue of real-time data processing, improving processing efficiency. However, Storm itself does not provide state management capabilities and is powerless in handling stateful computations such as aggregation. The emergence of Flink effectively addressed this shortcoming by introducing state management and checkpoint mechanisms, achieving efficient stateful stream computing capabilities."}),"\n",(0,t.jsx)(a.p,{children:"As real-time data processing scenarios evolve, particularly in real-time data warehousing scenarios, real-time\nrelational operations (i.e. stream join) increasingly become a challenge in realizing data real-time. Although Flink has excellent state management capabilities and outstanding performance, its performance bottleneck becomes more pronounced when handling join operations, especially when it involves three or more degrees of join. This is because each end of the join requires its own data state, and when there are multiple joins, the amount of data in the state increases significantly, making it difficult to accept in terms of performance. The root cause of this problem is that streaming computing systems like Flink use tables as their data model. However, the table model is a two-dimensional structure that does not include relationship definitions and storage, and when handling relationship operations, it can only be achieved through join operations, which incurs high costs."}),"\n",(0,t.jsx)(a.p,{children:"In Ant Financial's big data scenarios, particularly in financial risk control and real-time data warehousing, there\nare a large number of join operations, and how to improve the efficiency and performance of joins has become an important challenge we face. We have introduced the graph model, which is a data model that describes entity relationships using a point-edge structure. In the graph model, points represent entities, and edges represent relationships, and the data is stored together at the point-edge level. Therefore, the graph model naturally defines relationships and simultaneously materializes point-edge relationships at the storage level. Based on the graph model, we have implemented the next-generation real-time computing engine, GeaFlow, which effectively addresses the problem of complex relationship operations that traditional streaming computing engines face. Currently, GeaFlow has been widely used in scenarios such as data warehousing acceleration, financial risk control, knowledge graphs, and social networks."}),"\n",(0,t.jsx)(a.h2,{id:"architecture",children:"Architecture"}),"\n",(0,t.jsx)(a.p,{children:"The overall architecture of GeaFlow is as follows:"}),"\n",(0,t.jsx)(a.p,{children:(0,t.jsx)(a.img,{alt:"geaflow_arch",src:i(8731).A+"",width:"3528",height:"1934"})}),"\n",(0,t.jsxs)(a.ul,{children:["\n",(0,t.jsxs)(a.li,{children:[(0,t.jsx)(a.a,{href:"/tugraph-analytics/en/concepts/dsl_principle",children:"DSL Layer"}),": GeaFlow has designed a fusion analysis language, SQL+GQL, which supports unified processing of table models and graph models."]}),"\n",(0,t.jsxs)(a.li,{children:[(0,t.jsx)(a.a,{href:"/tugraph-analytics/en/concepts/framework_principle",children:"Framework Layer"}),": GeaFlow has designed two sets of APIs for graph and stream, supporting the fusion computation of streaming, batch, and graph processing. It has also implemented a unified distributed scheduling model based on Cycle."]}),"\n",(0,t.jsxs)(a.li,{children:[(0,t.jsx)(a.a,{href:"/tugraph-analytics/en/concepts/state_principle",children:"State Layer"}),": GeaFlow has designed two sets of APIs for graph and key-value storage, supporting the mixed storage of table data and graph data. The overall design follows the Sharing Nothing principle and supports the persistence of data to remote storage."]}),"\n",(0,t.jsxs)(a.li,{children:[(0,t.jsx)(a.a,{href:"/tugraph-analytics/en/concepts/console_principle",children:"Console Platform"}),": GeaFlow provides an all-in-one graph development platform, implementing the capabilities of graph data modeling, processing, and analysis. It also provides operational and control support for graph tasks."]}),"\n",(0,t.jsxs)(a.li,{children:[(0,t.jsx)(a.strong,{children:"Execution Environment"}),": GeaFlow can run in various heterogeneous execution environments, such as K8S, Ray, and local mode."]}),"\n"]}),"\n",(0,t.jsx)(a.h2,{id:"application-scenarios",children:"Application Scenarios"}),"\n",(0,t.jsx)(a.h3,{id:"real-time-data-warehouse-acceleration",children:"Real-time Data Warehouse Acceleration"}),"\n",(0,t.jsx)(a.p,{children:"In data warehouse scenarios, there are a large number of join operations, and in the DWD layer, it is often necessary to expand multiple tables into one large wide table to speed up subsequent queries. When the number of tables involved in a join increases, traditional real-time computing engines find it difficult to ensure the efficiency and performance of joins. This has become a challenging problem in the field of real-time data warehousing. GeaFlow's real-time graph computing engine can effectively address this problem. GeaFlow uses the graph as its data model, replacing the wide tables in the DWD layer, and can realize real-time graph construction. At the query stage, utilizing the point-edge materialization characteristics of the graph can greatly accelerate relationship operation queries. The following is the process diagram of GeaFlow's real-time data warehouse acceleration:"}),"\n",(0,t.jsx)(a.h3,{id:"real-time-attribution-analysis",children:"Real-time Attribution Analysis"}),"\n",(0,t.jsxs)(a.p,{children:["Under the background of informationization, channel attribution and path analysis of user behavior are the core of traffic analysis. By calculating the effective behavior path of users in real-time, and constructing a complete conversion path, it can quickly help businesses understand the value of products and assist operations in adjusting their strategies in a timely manner. The core points of real-time attribution analysis are accuracy and effectiveness. Accuracy requires ensuring the accuracy of user behavior path analysis under controllable costs. Effectiveness requires high real-time calculation to quickly assist business decision-making.\nBased on the capabilities of the GeaFlow's streaming computing, accurate and timely attribution analysis can be achieved. The following figure shows how this is accomplished:\n",(0,t.jsx)(a.img,{alt:"attribution_analysis",src:i(3790).A+"",width:"1166",height:"654"}),"\nFirstly, GeaFlow converts the user behavior logs into a user behavior topology graph in real-time, with users as the vertex and every behavior related to them as an the edge towards the buried page. Then, GeaFlow analyzes the subgraph of user behavior in advance using its streaming computing capability, and based on the attribution path matching rule, matches and calculates the attribution path of the corresponding user for the transaction behavior, and outputs it to the downstream systems."]}),"\n",(0,t.jsx)(a.h3,{id:"real-time-anti-crash-system",children:"Real-time Anti-Crash System"}),"\n",(0,t.jsxs)(a.p,{children:["In the context of credit risk management, detecting credit card cashing-out fraud is a typical risk management requirement. Based on analysis of existing cashing-out patterns, it can be seen that cashing-out is a loop subgraph. How to efficiently and quickly identify cashing-out in a large graph can greatly increase the efficiency of risk identification. Taking the following graph as an example, by transforming real-time transaction flows and transfer flows from input data sources into a real-time transaction graph, and then performing graph feature analysis on user transaction behavior based on risk management policies, such as loop checking and other feature calculations, real-time detection of cashing-out can be provided to decision-making and monitoring platforms. GeaFlow's real-time graph construction and calculation abilities can quickly identify abnormal transactional behaviors such as cashing-out, greatly reducing platform risk.\n",(0,t.jsx)(a.img,{alt:"real-anti-crash",src:i(2917).A+"",width:"1296",height:"694"})]})]})}function d(e={}){const{wrapper:a}={...(0,n.R)(),...e.components};return a?(0,t.jsx)(a,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},8453:(e,a,i)=>{i.d(a,{R:()=>r,x:()=>o});var t=i(6540);const n={},s=t.createContext(n);function r(e){const a=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),t.createElement(s.Provider,{value:a},e.children)}},8731:(e,a,i)=>{i.d(a,{A:()=>t});const t=i.p+"assets/images/geaflow_arch_new-cec9f72efc7816e0019a9fc3c7826ccf.png"}}]);